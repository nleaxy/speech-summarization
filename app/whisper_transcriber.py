# # import whisper
# # import librosa
# # import numpy as np
# # from pathlib import Path
# # import json
# # from datetime import datetime

# # def transcribe_with_librosa(audio_file):
# #     """
# #     Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ librosa Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾
    
# #     Args:
# #         audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ñƒ
        
# #     Returns:
# #         Dict Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
# #     """
# #     try:
# #         # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°
# #         if not Path(audio_file).exists():
# #             raise FileNotFoundError(f"Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {audio_file}")
        
# #         # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
# #         model = whisper.load_model("base")
        
# #         # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· librosa
# #         print("ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· librosa...")
# #         audio_data, sample_rate = librosa.load(audio_file, sr=16000)
# #         audio_data = audio_data.astype(np.float32)
        
# #         # Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ
# #         print("ğŸµ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ...")
# #         result = model.transcribe(audio_data)
        
# #         print("âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!")
# #         return result
        
# #     except Exception as e:
# #         print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
# #         return None

# # def save_to_json(result, output_file="transcription_result.json"):
# #     """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸ Ğ² JSON Ñ„Ğ°Ğ¹Ğ»"""
# #     if result:
# #         # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
# #         result_with_meta = {
# #             "metadata": {
# #                 "timestamp": datetime.now().isoformat(),
# #                 "audio_file": audio_file,
# #                 "model": "whisper-base"
# #             },
# #             "transcription": result
# #         }
        
# #         with open(output_file, 'w', encoding='utf-8') as f:
# #             json.dump(result_with_meta, f, ensure_ascii=False, indent=2)
        
# #         print(f"ğŸ’¾ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ²: {output_file}")
# #         return True
# #     else:
# #         print("âŒ ĞĞµÑ‡ĞµĞ³Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑŒ - Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹")
# #         return False

# # def print_text_only(result):
# #     """Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚"""
# #     if result and "text" in result:
# #         print("\n" + "="*50)
# #         print("ğŸ“ Ğ ĞĞ¡ĞŸĞĞ—ĞĞĞĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢:")
# #         print("="*50)
# #         print(result["text"])
# #         print("="*50)
# #     else:
# #         print("âŒ Ğ¢ĞµĞºÑÑ‚ Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ½")

# # # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ´
# # if __name__ == "__main__":
# #     audio_file = "test.wav"  # Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ²Ğ°Ñˆ Ñ„Ğ°Ğ¹Ğ»
    
# #     # Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ
# #     result = transcribe_with_librosa(audio_file)
    
# #     if result:
# #         # 1. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² JSON
# #         save_to_json(result, "transcription_result.json")
        
# #         # 2. Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑÑ‚(Ğ´Ğ»Ñ ĞÑƒÑ…Ğ±.)
# #         print_text_only(result)
        
# #     else:
# #         print("âŒ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
# import whisper
# import librosa
# import numpy as np
# from pathlib import Path
# import json
# from datetime import datetime
# import random

# def transcribe_with_librosa(audio_file):
#     """
#     Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ librosa Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾
    
#     Args:
#         audio_file: ĞŸÑƒÑ‚ÑŒ Ğº Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ñƒ
        
#     Returns:
#         Dict Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ None Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
#     """
#     try:
#         # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°
#         if not Path(audio_file).exists():
#             raise FileNotFoundError(f"Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {audio_file}")
        
#         # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²
#         supported_formats = {'.wav', '.mp3'}
#         file_extension = Path(audio_file).suffix.lower()
        
#         if file_extension not in supported_formats:
#             raise ValueError(f"ĞĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚: {file_extension}. "
#                            f"ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ: {', '.join(supported_formats)}")
        
#         # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
#         model = whisper.load_model("base")
        
#         # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· librosa
#         print("ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡ĞµÑ€ĞµĞ· librosa...")
#         audio_data, sample_rate = librosa.load(audio_file, sr=16000)
#         audio_data = audio_data.astype(np.float32)
        
#         # Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ
#         print("ğŸµ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ...")
#         result = model.transcribe(audio_data)
        
#         # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²
#         result = add_speaker_diarization(result)
        
#         print("âœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!")
#         return result
        
#     except Exception as e:
#         print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
#         return None

# def add_speaker_diarization(transcription):
#     """
#     Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ² Ğº Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñƒ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸
#     """
#     speakers = ["SPEAKER_01", "SPEAKER_02"]
#     current_speaker = speakers[0]
    
#     for i, segment in enumerate(transcription.get("segments", [])):
#         # ĞœĞµĞ½ÑĞµĞ¼ Ğ³Ğ¾Ğ²Ğ¾Ñ€ÑÑ‰ĞµĞ³Ğ¾ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 2 ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°
#         if i > 0 and i % 2 == 0:
#             current_speaker = speakers[1] if current_speaker == speakers[0] else speakers[0]
        
#         segment["speaker"] = current_speaker
    
#     transcription["speakers"] = speakers
#     return transcription

# def save_to_json(result, output_file="transcription_result.json"):
#     """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ğ¸ Ğ² JSON Ñ„Ğ°Ğ¹Ğ»"""
#     if result:
#         # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
#         result_with_meta = {
#             "metadata": {
#                 "timestamp": datetime.now().isoformat(),
#                 "audio_file": audio_file,
#                 "model": "whisper-base",
#                 "speakers_count": len(result.get("speakers", []))
#             },
#             "transcription": result
#         }
        
#         with open(output_file, 'w', encoding='utf-8') as f:
#             json.dump(result_with_meta, f, ensure_ascii=False, indent=2)
        
#         print(f"ğŸ’¾ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ²: {output_file}")
#         return True
#     else:
#         print("âŒ ĞĞµÑ‡ĞµĞ³Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑŒ - Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹")
#         return False

# def print_text_only(result):
#     """Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚"""
#     if result and "text" in result:
#         print("\n" + "="*50)
#         print("ğŸ“ Ğ ĞĞ¡ĞŸĞĞ—ĞĞĞĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢:")
#         print("="*50)
#         print(result["text"])
#         print("="*50)
#     else:
#         print("âŒ Ğ¢ĞµĞºÑÑ‚ Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ½")

# def print_text_with_speakers(result):
#     """Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ñ‚ĞµĞºÑÑ‚ Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ°Ğ¼"""
#     if result and "segments" in result:
#         print("\n" + "="*60)
#         print("ğŸ­ Ğ¢Ğ•ĞšĞ¡Ğ¢ Ğ¡ Ğ ĞĞ¡ĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ•Ğœ ĞŸĞ Ğ“ĞĞ›ĞĞ¡ĞĞœ:")
#         print("="*60)
        
#         for segment in result["segments"]:
#             speaker = segment.get("speaker", "UNKNOWN")
#             text = segment.get("text", "").strip()
#             if text:
#                 print(f"[{speaker}]: {text}")
        
#         print("="*60)
#         print(f"ğŸ—£ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€ÑÑ‰Ğ¸Ñ…: {len(result.get('speakers', []))}")

# # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ´
# if __name__ == "__main__":
#     audio_file = "razgovor-sotrudnikov-ooo-_ntk-sibir_-supervayzer-mutit.mp3"  # Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ²Ğ°Ñˆ Ñ„Ğ°Ğ¹Ğ» (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ .wav Ğ¸Ğ»Ğ¸ .mp3)
    
#     # Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ
#     result = transcribe_with_librosa(audio_file)
    
#     if result:
#         # 1. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² JSON
#         save_to_json(result, "transcription_result.json")
        
#         # 2. Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑÑ‚(Ğ´Ğ»Ñ ĞÑƒÑ…Ğ±.)
#         print_text_only(result)
        
#         # 3. Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚ĞµĞºÑÑ‚ Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾ Ğ³Ğ¾Ğ»Ğ¾ÑĞ°Ğ¼
#         print_text_with_speakers(result)
        
#     else:
#         print("âŒ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
import whisper
import librosa
import numpy as np
from pathlib import Path
import json
import random

def transcribe_with_librosa(audio_file):
    """
    Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ librosa Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾
    """
    try:
        if not Path(audio_file).exists():
            raise FileNotFoundError(f"Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {audio_file}")
        
        supported_formats = {'.wav', '.mp3'}
        file_extension = Path(audio_file).suffix.lower()
        
        if file_extension not in supported_formats:
            raise ValueError(f"ĞĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚: {file_extension}")
        
        model = whisper.load_model("base")
        
        audio_data, sample_rate = librosa.load(audio_file, sr=16000)
        audio_data = audio_data.astype(np.float32)
        
        result = model.transcribe(audio_data)
        result = add_speaker_diarization(result)
        
        return result
        
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return None

def add_speaker_diarization(transcription):
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²"""
    speakers = ["SPEAKER_01", "SPEAKER_02"]
    current_speaker = speakers[0]
    
    for i, segment in enumerate(transcription.get("segments", [])):
        if i > 0 and i % 2 == 0:
            current_speaker = speakers[1] if current_speaker == speakers[0] else speakers[0]
        segment["speaker"] = current_speaker
    
    transcription["speakers"] = speakers
    return transcription

def save_simple_json(result, output_file="transcription_simple.json"):
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ ÑƒĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ñ‹Ğ¹ JSON"""
    if result:
        simple_result = {
            "text": result.get("text", ""),
            "language": result.get("language", ""),
            "segments": [
                {
                    "start": segment.get("start", 0),
                    "end": segment.get("end", 0),
                    "text": segment.get("text", ""),
                    "speaker": segment.get("speaker", "")
                }
                for segment in result.get("segments", [])
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(simple_result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ JSON ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ²: {output_file}")
        return True
    return False

# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ´
if __name__ == "__main__":
    audio_file = "razgovor-sotrudnikov-ooo-_ntk-sibir_-supervayzer-mutit.mp3"
    
    result = transcribe_with_librosa(audio_file)
    
    if result:
        save_simple_json(result)
        
        print("\nğŸ“ Ğ ĞĞ¡ĞŸĞĞ—ĞĞĞĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢:")
        print(result["text"])
        
        print("\nğŸ­ Ğ¢Ğ•ĞšĞ¡Ğ¢ Ğ¡ Ğ“ĞĞ›ĞĞ¡ĞĞœĞ˜:")
        for segment in result["segments"]:
            print(f"[{segment['speaker']}]: {segment['text']}")