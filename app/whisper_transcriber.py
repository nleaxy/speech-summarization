# # import whisper
# # import librosa
# # import numpy as np
# # from pathlib import Path
# # import json
# # from datetime import datetime

# # def transcribe_with_librosa(audio_file):
# #     """
# #     –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º librosa –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ
    
# #     Args:
# #         audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        
# #     Returns:
# #         Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
# #     """
# #     try:
# #         # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
# #         if not Path(audio_file).exists():
# #             raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
        
# #         # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# #         model = whisper.load_model("base")
        
# #         # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ librosa
# #         print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ librosa...")
# #         audio_data, sample_rate = librosa.load(audio_file, sr=16000)
# #         audio_data = audio_data.astype(np.float32)
        
# #         # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
# #         print("üéµ –ù–∞—á–∏–Ω–∞—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é...")
# #         result = model.transcribe(audio_data)
        
# #         print("‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
# #         return result
        
# #     except Exception as e:
# #         print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
# #         return None

# # def save_to_json(result, output_file="transcription_result.json"):
# #     """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤ JSON —Ñ–∞–π–ª"""
# #     if result:
# #         # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
# #         result_with_meta = {
# #             "metadata": {
# #                 "timestamp": datetime.now().isoformat(),
# #                 "audio_file": audio_file,
# #                 "model": "whisper-base"
# #             },
# #             "transcription": result
# #         }
        
# #         with open(output_file, 'w', encoding='utf-8') as f:
# #             json.dump(result_with_meta, f, ensure_ascii=False, indent=2)
        
# #         print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
# #         return True
# #     else:
# #         print("‚ùå –ù–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—É—Å—Ç–æ–π")
# #         return False

# # def print_text_only(result):
# #     """–í—ã–≤–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"""
# #     if result and "text" in result:
# #         print("\n" + "="*50)
# #         print("üìù –†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢:")
# #         print("="*50)
# #         print(result["text"])
# #         print("="*50)
# #     else:
# #         print("‚ùå –¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")

# # # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥
# # if __name__ == "__main__":
# #     audio_file = "test.wav"  # –£–∫–∞–∂–∏—Ç–µ –≤–∞—à —Ñ–∞–π–ª
    
# #     # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
# #     result = transcribe_with_librosa(audio_file)
    
# #     if result:
# #         # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON
# #         save_to_json(result, "transcription_result.json")
        
# #         # 2. –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç(–¥–ª—è –ù—É—Ö–±.)
# #         print_text_only(result)
        
# #     else:
# #         print("‚ùå –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
# import whisper
# import librosa
# import numpy as np
# from pathlib import Path
# import json
# from datetime import datetime
# import random

# def transcribe_with_librosa(audio_file):
#     """
#     –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º librosa –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ
    
#     Args:
#         audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        
#     Returns:
#         Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
#     """
#     try:
#         # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
#         if not Path(audio_file).exists():
#             raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
        
#         # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
#         supported_formats = {'.wav', '.mp3'}
#         file_extension = Path(audio_file).suffix.lower()
        
#         if file_extension not in supported_formats:
#             raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_extension}. "
#                            f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: {', '.join(supported_formats)}")
        
#         # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
#         model = whisper.load_model("base")
        
#         # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ librosa
#         print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ librosa...")
#         audio_data, sample_rate = librosa.load(audio_file, sr=16000)
#         audio_data = audio_data.astype(np.float32)
        
#         # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
#         print("üéµ –ù–∞—á–∏–Ω–∞—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é...")
#         result = model.transcribe(audio_data)
        
#         # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤
#         result = add_speaker_diarization(result)
        
#         print("‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
#         return result
        
#     except Exception as e:
#         print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
#         return None

# def add_speaker_diarization(transcription):
#     """
#     –î–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤ –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
#     """
#     speakers = ["SPEAKER_01", "SPEAKER_02"]
#     current_speaker = speakers[0]
    
#     for i, segment in enumerate(transcription.get("segments", [])):
#         # –ú–µ–Ω—è–µ–º –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –∫–∞–∂–¥—ã–µ 2 —Å–µ–≥–º–µ–Ω—Ç–∞
#         if i > 0 and i % 2 == 0:
#             current_speaker = speakers[1] if current_speaker == speakers[0] else speakers[0]
        
#         segment["speaker"] = current_speaker
    
#     transcription["speakers"] = speakers
#     return transcription

# def save_to_json(result, output_file="transcription_result.json"):
#     """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤ JSON —Ñ–∞–π–ª"""
#     if result:
#         # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
#         result_with_meta = {
#             "metadata": {
#                 "timestamp": datetime.now().isoformat(),
#                 "audio_file": audio_file,
#                 "model": "whisper-base",
#                 "speakers_count": len(result.get("speakers", []))
#             },
#             "transcription": result
#         }
        
#         with open(output_file, 'w', encoding='utf-8') as f:
#             json.dump(result_with_meta, f, ensure_ascii=False, indent=2)
        
#         print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
#         return True
#     else:
#         print("‚ùå –ù–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—É—Å—Ç–æ–π")
#         return False

# def print_text_only(result):
#     """–í—ã–≤–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"""
#     if result and "text" in result:
#         print("\n" + "="*50)
#         print("üìù –†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢:")
#         print("="*50)
#         print(result["text"])
#         print("="*50)
#     else:
#         print("‚ùå –¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")

# def print_text_with_speakers(result):
#     """–í—ã–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –≥–æ–ª–æ—Å–∞–º"""
#     if result and "segments" in result:
#         print("\n" + "="*60)
#         print("üé≠ –¢–ï–ö–°–¢ –° –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï–ú –ü–û –ì–û–õ–û–°–ê–ú:")
#         print("="*60)
        
#         for segment in result["segments"]:
#             speaker = segment.get("speaker", "UNKNOWN")
#             text = segment.get("text", "").strip()
#             if text:
#                 print(f"[{speaker}]: {text}")
        
#         print("="*60)
#         print(f"üó£Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≥–æ–≤–æ—Ä—è—â–∏—Ö: {len(result.get('speakers', []))}")

# # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥
# if __name__ == "__main__":
#     audio_file = "razgovor-sotrudnikov-ooo-_ntk-sibir_-supervayzer-mutit.mp3"  # –£–∫–∞–∂–∏—Ç–µ –≤–∞—à —Ñ–∞–π–ª (–º–æ–∂–Ω–æ .wav –∏–ª–∏ .mp3)
    
#     # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
#     result = transcribe_with_librosa(audio_file)
    
#     if result:
#         # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON
#         save_to_json(result, "transcription_result.json")
        
#         # 2. –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç(–¥–ª—è –ù—É—Ö–±.)
#         print_text_only(result)
        
#         # 3. –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –≥–æ–ª–æ—Å–∞–º
#         print_text_with_speakers(result)
        
#     else:
#         print("‚ùå –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
import whisper
import librosa
import numpy as np
from pathlib import Path
import json
import random

def transcribe_with_librosa(audio_file):
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º librosa –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ
    """
    try:
        if not Path(audio_file).exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
        
        supported_formats = {'.wav', '.mp3'}
        file_extension = Path(audio_file).suffix.lower()
        
        if file_extension not in supported_formats:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_extension}")
        
        model = whisper.load_model("base")
        
        audio_data, sample_rate = librosa.load(audio_file, sr=16000)
        audio_data = audio_data.astype(np.float32)
        
        result = model.transcribe(audio_data)
        result = add_speaker_diarization(result)
        
        return result
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

def add_speaker_diarization(transcription):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤"""
    speakers = ["SPEAKER_01", "SPEAKER_02"]
    current_speaker = speakers[0]
    
    for i, segment in enumerate(transcription.get("segments", [])):
        if i > 0 and i % 2 == 0:
            current_speaker = speakers[1] if current_speaker == speakers[0] else speakers[0]
        segment["speaker"] = current_speaker
    
    transcription["speakers"] = speakers
    return transcription

def save_simple_json(result, output_file="transcription_simple.json"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π JSON"""
    if result:
        simple_result = {
            "text": result.get("text", ""),
            "language": result.get("language", ""),
            "segments": [
                {
                    "start": segment.get("start", 0),
                    "end": segment.get("end", 0),
                    "text": segment.get("text", ""),
                    "speaker": segment.get("speaker", "")
                }
                for segment in result.get("segments", [])
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(simple_result, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
        return True
    return False

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥
if __name__ == "__main__":
    audio_file = "razgovor-sotrudnikov-ooo-_ntk-sibir_-supervayzer-mutit.mp3"
    
    result = transcribe_with_librosa(audio_file)
    
    if result:
        save_simple_json(result)
        
        print("\nüìù –†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢:")
        print(result["text"])
        
        print("\nüé≠ –¢–ï–ö–°–¢ –° –ì–û–õ–û–°–ê–ú–ò:")
        for segment in result["segments"]:
            print(f"[{segment['speaker']}]: {segment['text']}")